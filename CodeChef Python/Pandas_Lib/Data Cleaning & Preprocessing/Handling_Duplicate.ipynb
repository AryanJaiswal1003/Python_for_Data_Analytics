{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d6dc33",
   "metadata": {},
   "source": [
    "### **Identifying Duplicate Rows**\n",
    "Duplicate rows in a **Pandas DataFrame** occur when one or more rows contain the **same values across all columns** (or a selected subset of columns). Detecting duplicates is a crucial step in **data cleaning** to ensure data accuracy and reliability.\n",
    "\n",
    "---\n",
    "‚úÖ **Key Points**\n",
    "* `df.duplicated()` checks **all columns** by default.\n",
    "* `df.duplicated(subset=['column_name'])` limits the check to specific columns.\n",
    "* Use `df.duplicated(keep=False)` to flag **all** duplicates (including the first occurrence).\n",
    "* Combine with `df[df.duplicated()]` to **view** the duplicate rows.\n",
    "---\n",
    "##### ‚û°Ô∏è **Methods for Identifying Duplicates**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07559b0",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **1. Using `duplicated()` Method**\n",
    "\n",
    "The `duplicated()` method returns a **boolean Series** indicating whether each row is a duplicate of any of the previous rows.\n",
    "* By default, **all columns** are checked for duplication.\n",
    "* The **first occurrence** of each duplicate is **not marked** as a duplicate (it is considered unique).\n",
    "* Only the **subsequent occurrences** are flagged as `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23a4865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob'],\n",
    "    'Age': [25, 30, 25, 35, 30],\n",
    "    'City': ['NY', 'LA', 'NY', 'SF', 'LA']\n",
    "})\n",
    "\n",
    "# Identify duplicate rows (across all columns)\n",
    "duplicates = df.duplicated()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904f53b",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **2. Using `subset` Parameter**\n",
    "\n",
    "You can specify a **subset of columns** to check for duplicates using the `subset` parameter. This is useful when only specific columns need to be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5134fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Alice', 'Charlie', 'Bob'],\n",
    "    'Age': [25, 30, 25, 35, 30],\n",
    "    'City': ['NY', 'LA', 'NY', 'SF', 'LA']\n",
    "})\n",
    "# Identify duplicates based on the 'Name' column\n",
    "duplicates_name = df.duplicated(subset=['Name'])\n",
    "print(duplicates_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75e9ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   A  B\n",
      "0  1  a\n",
      "1  2  b\n",
      "2  2  c\n",
      "3  3  c\n",
      "4  4  d\n",
      "5  3  e\n",
      "6  2  b\n",
      "\n",
      "Duplicate rows:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "5    False\n",
      "6     True\n",
      "dtype: bool\n",
      "\n",
      "Duplicates based on column 'A':\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "5     True\n",
      "6     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3, 4, 3, 2],\n",
    "    'B': ['a', 'b', 'c', 'c', 'd', 'e', 'b']\n",
    "})\n",
    "duplicates = df.duplicated() # Identify duplicates\n",
    "duplicates_A = df.duplicated(subset=['A']) # Identify duplicates based only on column 'A'\n",
    "\n",
    "print(\n",
    "    f\"Original DataFrame:\\n{df}\\n\"\n",
    "    f\"\\nDuplicate rows:\\n{duplicates}\\n\" # Identify duplicates\n",
    "    f\"\\nDuplicates based on column 'A':\\n{duplicates_A}\" # Identify duplicates based only on column 'A'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e77ae1",
   "metadata": {},
   "source": [
    "### **Removing Duplicate Rows**\n",
    "\n",
    "Once **duplicate rows** are identified in a Pandas DataFrame, you can remove them to ensure data quality and consistency.\n",
    "Pandas provides flexible methods to remove duplicates without altering the original data unless explicitly instructed.\n",
    "\n",
    "---\n",
    "‚úÖ **Key Takeaways**\n",
    "* `drop_duplicates()` helps remove duplicate rows easily.\n",
    "* The original DataFrame remains unchanged unless you use `inplace=True`.\n",
    "* Use the **`subset`** parameter for column-specific duplicate removal.\n",
    "* The **`keep`** parameter provides flexibility in which duplicate entries to retain.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509422f",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **1. Using `drop_duplicates()`**\n",
    "\n",
    "The simplest way to remove duplicates is by using the **`drop_duplicates()`** method. It removes all duplicate rows and returns a **new DataFrame**, while keeping the original unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64468c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  x\n",
      "1  2  y\n",
      "3  3  z\n",
      "4  4  x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3, 4, 4],\n",
    "    'B': ['x', 'y', 'y', 'z', 'x', 'x']\n",
    "})\n",
    "\n",
    "# Remove duplicate rows\n",
    "df_unique = df.drop_duplicates()\n",
    "print(df_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54309461",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **2. Keeping Specific Duplicates**\n",
    "\n",
    "You can control which duplicates to retain using the **`keep`** parameter.\n",
    "* `keep='first'`: Keeps the first occurrence and removes later duplicates.\n",
    "* `keep='last'`: Keeps the last occurrence and removes earlier duplicates.\n",
    "* `keep=False`: Removes **all** occurrences of duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d8d6c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep First Occurence of Duplicates:\n",
      "   A  B\n",
      "0  1  x\n",
      "1  2  y\n",
      "3  3  z\n",
      "4  4  x\n",
      "\n",
      "Keep Last Occurrence of Duplicates:\n",
      "   A  B\n",
      "0  1  x\n",
      "2  2  y\n",
      "3  3  z\n",
      "5  4  x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3, 4, 4],\n",
    "    'B': ['x', 'y', 'y', 'z', 'x', 'x']\n",
    "})\n",
    "# Keep first occurrence of duplicates\n",
    "df_keep_first = df.drop_duplicates(keep='first')\n",
    "print(f\"Keep First Occurence of Duplicates:\\n{df_keep_first}\\n\")\n",
    "\n",
    "# Keep last occurrence of duplicates\n",
    "df_keep_last = df.drop_duplicates(keep='last')\n",
    "print(f\"Keep Last Occurrence of Duplicates:\\n{df_keep_last}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdbf402",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **3. Using `subset` Parameter**\n",
    "\n",
    "If you want to consider only specific columns while identifying duplicates, use the **`subset`** parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7635d7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing duplicates based only on column 'A':\n",
      "   A  B\n",
      "0  1  x\n",
      "1  2  y\n",
      "3  3  z\n",
      "4  4  x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3, 4, 4],\n",
    "    'B': ['x', 'y', 'y', 'z', 'x', 'x']\n",
    "})\n",
    "\n",
    "# Remove duplicates based only on column 'A'\n",
    "df_unique_A = df.drop_duplicates(subset=['A'])\n",
    "print(f\"Removing duplicates based only on column 'A':\\n{df_unique_A}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0155fed",
   "metadata": {},
   "source": [
    "üîπ **`Problem:` The DataFrame has duplicate entries for some students with different grades.**\n",
    "\n",
    "Remove **duplicates based on 'Student_ID'**, **keeping the entry with the highest grade** for each student. \n",
    "\n",
    "In order to get the highest grade for each student - you will have to **first sort the dataframe with Student_ID and Grade in descending** order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f857d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame after Sorting Student_ID [asc] & Grade [desc]:\n",
      "   Student_ID     Name  Grade\n",
      "3           1    Alice     88\n",
      "0           1    Alice     85\n",
      "1           2      Bob     92\n",
      "4           2      Bob     90\n",
      "2           3  Charlie     78\n",
      "5           4    David     95\n",
      "\n",
      "Removing Duplicates on Student_ID, Keeping the Highest Grade entry [Descending Order]:\n",
      "   Student_ID     Name  Grade\n",
      "3           1    Alice     88\n",
      "1           2      Bob     92\n",
      "2           3  Charlie     78\n",
      "5           4    David     95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Student_ID': [1, 2, 3, 1, 2, 4],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'Bob', 'David'],\n",
    "    'Grade': [85, 92, 78, 88, 90, 95]\n",
    "})\n",
    "# Sorting the dataframe with Student_ID and Grade in descending order.\n",
    "df_sorted = df.sort_values(by=['Student_ID', 'Grade'], ascending=[True, False])\n",
    "print(f\"Original DataFrame after Sorting Student_ID [asc] & Grade [desc]:\\n{df_sorted}\\n\")\n",
    "\n",
    "# Removing duplicates based on 'Student_ID', keeping the entry with the highest grade for each student.\n",
    "df_removed = df_sorted.drop_duplicates(subset=['Student_ID'], keep='first')\n",
    "print(f\"Removing Duplicates on Student_ID, Keeping the Highest Grade entry [Descending Order]:\\n{df_removed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525a61a2",
   "metadata": {},
   "source": [
    "### **Handling Duplicates in Index**\n",
    "In Pandas, the **index** uniquely identifies each row.\n",
    "However, sometimes during data loading, merging, or transformation, **duplicate index values** can appear.\n",
    "These duplicates can cause problems during operations like **joining**, **reindexing**, or **data alignment** ‚Äî so detecting and handling them is important.\n",
    "\n",
    "---\n",
    "‚úÖ **Key Takeaways**\n",
    "* **Duplicate indexes** can cause alignment and merge issues in Pandas.\n",
    "* Use **`index.duplicated()`** to detect them.\n",
    "* Use boolean masking or **`reset_index()`** to clean or reset the index.\n",
    "* Always ensure your index is **unique and meaningful** when performing operations like joins or merges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce20c47",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **1. Identifying Duplicate Index Values**\n",
    "\n",
    "You can check for duplicates in the DataFrame index using the **`index.duplicated()`** property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb55b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with duplicate index values\n",
    "df = pd.DataFrame({\n",
    "    'A': [10, 20, 30, 40],\n",
    "    'B': [5, 6, 7, 8]\n",
    "}, index=['a', 'b', 'b', 'c'])\n",
    "\n",
    "# Identify duplicate index values\n",
    "print(df.index.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a794a",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **2. Filtering Out Duplicate Index Rows**\n",
    "\n",
    "To remove rows with duplicate index values, use boolean indexing, You can also specify:\n",
    "* `keep='last'` ‚Üí Keeps the last occurrence.\n",
    "* `keep=False` ‚Üí Removes *all* duplicate index entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f6bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A  B\n",
      "b  30  7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with duplicate index values\n",
    "df = pd.DataFrame({\n",
    "    'A': [10, 20, 30, 40],\n",
    "    'B': [5, 6, 7, 8]\n",
    "}, index=['a', 'b', 'b', 'c'])\n",
    "\n",
    "# Keep only the first occurrence of each index\n",
    "df_no_dup_index = df[df.index.duplicated(keep='first')]\n",
    "print(df_no_dup_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80cf8d6",
   "metadata": {},
   "source": [
    "‚û°Ô∏è **3. Resetting the Index**\n",
    "\n",
    "If duplicate index values aren‚Äôt meaningful, you can **reset the index** entirely.\n",
    "* `drop=True` ‚Üí Removes the old index instead of adding it as a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6470e424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A  B\n",
      "0  10  5\n",
      "1  20  6\n",
      "2  30  7\n",
      "3  40  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame with duplicate index values\n",
    "df = pd.DataFrame({\n",
    "    'A': [10, 20, 30, 40],\n",
    "    'B': [5, 6, 7, 8]\n",
    "}, index=['a', 'b', 'b', 'c'])\n",
    "\n",
    "df_reset = df.reset_index(drop=True)\n",
    "print(df_reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96aa500e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying the duplicate indices: Index(['a'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with duplicate indices\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Edward'],\n",
    "    'Age': [25, 30, 35, 40, 45]\n",
    "}\n",
    "# Creating a DataFrame with duplicate indices\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c', 'a', 'e'])\n",
    "\n",
    "# Identifying duplicate indices\n",
    "duplicate_indices = df.index[df.index.duplicated()].unique()\n",
    "\n",
    "print(f\"Displaying the duplicate indices: {duplicate_indices}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
